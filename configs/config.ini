[SELECTION]
author_match_score = 15.0
run_openai = true
# DO NOT USE GPT 3.5 TURBO EXCEPT FOR DEBUGGING
#model = gpt-3.5-turbo
#model = gpt-3.5-turbo-1106
#model = gpt-4
#model = gpt-4-1106-preview
#model = gpt-4o
#model = deepseek-reasoner
model = deepseek-chat
# cost quality tradeoff - larger batches are cheaper but less accurate.
batch_size = 5

[FILTERING]
arxiv_category = cs.CL,cs.ML,cs.AI,cs.IR,cs.CY,cs.HC,cs.CR,cs.CE
#arxiv_category = cs.CL
# force_primary ignores papers that are only cross-listed into the arxiv_category
force_primary = true
# draws num_samples samples from the LM and averages scores
num_samples = 1
hcutoff = 10
relevance_cutoff = 3
novelty_cutoff = 3
# whether to do author matching
author_match = true
max_papers_per_day = 50

[OUTPUT]
debug_messages = true
dump_debug_file = true
output_path = out/
# options: json, md, slack
dump_json = true
dump_md = false
push_to_slack = true
push_to_email = true
recipient_email_address = zzhu41@stevens.edu